{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext bigquery_magics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Will it snow tomorrow?\" - The time traveler asked\n",
    "The following dataset contains climate information from over 9000 stations accross the world. The overall goal of these subtasks will be to predict whether it will snow tomorrow 20 years ago. So if today is 1 April 2025 then the weather we want to forecast is for the 2 April 2005. You are supposed to solve the tasks using Big Query, which can be used in the Jupyter Notebook like it is shown in the following cell. For further information and how to use BigQuery in Jupyter Notebook refer to the Google Docs. \n",
    "\n",
    "The goal of this test is to test your coding knowledge in Python, BigQuery and Pandas as well as your understanding of Data Science. If you get stuck in the first part, you can use the replacement data provided in the second part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "SELECT\n",
    "*,\n",
    "FROM `bigquery-public-data.samples.gsod`\n",
    "LIMIT 20 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Task\n",
    "Change the date format to 'YYYY-MM-DD' and select the data from 2000 till 2005 for station numbers including and between 725300 and 726300 , and save it as a pandas dataframe. Note the maximum year available is 2010. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery df\n",
    "SELECT *,\n",
    "FORMAT_DATE('%Y-%m-%d', DATE(year, month, day)) AS date, #Add new column with new date format \n",
    "FROM `bigquery-public-data.samples.gsod`\n",
    "WHERE year BETWEEN 2000 AND 2005 \n",
    "    AND station_number BETWEEN 725300 AND 726300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the first rows of the created dataframe \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Task \n",
    "From here you want to work with the data from all stations 725300 to 725330 that have information from 2000 till 2005. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery df\n",
    "SELECT *,\n",
    "    FORMAT_DATE('%Y-%m-%d', DATE(year, month, day)) AS date,\n",
    "FROM `bigquery-public-data.samples.gsod`\n",
    "WHERE station_number BETWEEN 725300 AND 725330\n",
    "    AND year BETWEEN 2000 AND 2005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check general information of the new df\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by checking which year received the most snowfall in our data.Â "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "SELECT year,\n",
    "    COUNT(snow) AS nr_snowfall, #Count snowfall events\n",
    "FROM `bigquery-public-data.samples.gsod`\n",
    "WHERE station_number BETWEEN 725300 AND 725330\n",
    "    AND year BETWEEN 2000 AND 2005\n",
    "GROUP BY year \n",
    "ORDER BY nr_snowfall DESC #Order snowfall from largest to smallest\n",
    "LIMIT 1 #Limit query result to the first row, which correspond to the highest number of snowfall events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add an additional field that indicates the daily change in snow depth measured at every station. And identify the station and day for which the snow depth increased the most.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "WITH snow_depth_daily_change AS ( #Use temporary result query to simplify the process of next queries \n",
    "    SELECT station_number,\n",
    "        FORMAT_DATE('%Y-%m-%d', DATE(year, month, day)) AS date,\n",
    "        snow_depth,\n",
    "        #Get the snow depth of previous day for the same station\n",
    "        LAG(snow_depth, 1) OVER (PARTITION BY station_number ORDER BY year, month, day) AS prev_snow_depth,\n",
    "        #Compute daily change in snow depth by subtracting the snow depth of the previous day from the current day at the same station\n",
    "        snow_depth - LAG(snow_depth, 1) OVER (PARTITION BY station_number ORDER BY year, month, day) AS snow_depth_change\n",
    "    FROM `bigquery-public-data.samples.gsod`\n",
    "    WHERE station_number BETWEEN 725300 AND 725330\n",
    "        AND year BETWEEN 2000 AND 2005\n",
    "    )\n",
    "\n",
    "#Get station and date with highest snow depth increase \n",
    "SELECT station_number,\n",
    "    date,\n",
    "    snow_depth_change\n",
    "FROM snow_depth_daily_change #Take data from temporary query above \n",
    "WHERE snow_depth_change IS NOT NULL #Filter only not null snow depth changes\n",
    "ORDER BY snow_depth_change DESC \n",
    "LIMIT 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do further checks on the remaining dataset, clean or drop data depending on how you see appropriate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "pd.set_option(\"display.max.columns\", None) #Display all columns of dataframes\n",
    "pd.set_option(\"display.max.rows\", None) #Display all rows of dataframes\n",
    "\n",
    "#Check general info on the df and unique values for each column\n",
    "df.info()\n",
    "df.nunique()\n",
    "\n",
    "#Check for duplicated rows and drop them\n",
    "df.duplicated().sum()\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "#Check for missing values in each columns\n",
    "df.isnull().sum()\n",
    "\n",
    "#Drop columns having missing values >50%, they can skew analysis and reduce accuracy of the ML model\n",
    "#Inspect the potentially important columns which have a high number of missing values\n",
    "df['snow_depth'].isna().groupby(df['station_number']).mean()\n",
    "final_df = df.drop(['min_temperature','min_temperature_explicit', 'mean_station_pressure', 'num_mean_station_pressure_samples', 'snow_depth'], axis=1)\n",
    "#Dropped snow_depth due to >90% missingness across all stations\n",
    "#Handle missing values with imputation techniques \n",
    "#Impute numeric values for each station by using interpolation\n",
    "final_df['max_gust_wind_speed'] = final_df.groupby('station_number')['max_gust_wind_speed'].transform(lambda x: x.interpolate(limit_direction='both'))\n",
    "final_df['mean_sealevel_pressure'] = final_df.groupby('station_number')['mean_sealevel_pressure'].transform(lambda x: x.interpolate(limit_direction='both'))\n",
    "final_df['num_mean_sealevel_pressure_samples'] = final_df.groupby('station_number')['num_mean_sealevel_pressure_samples'].transform(lambda x: x.interpolate(limit_direction='both'))\n",
    "\n",
    "#Standardize the representation of missing values to avoid potential bugs \n",
    "final_df = final_df.mask(final_df.isna(), np.nan) #Replace all missing values with NaN from numpy\n",
    "\n",
    "#Check stored data per station\n",
    "#If necessary, drop stations with too little data\n",
    "data_per_station = final_df['station_number'].value_counts()\n",
    "#display(data_per_station)\n",
    "\n",
    "#Sort dataframe based on station numbers and date for better clarity\n",
    "df = df.sort_values(by=['station_number', 'date']).reset_index(drop=True)\n",
    "#Convert column date from object type to datetime type\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "#Check for gaps in consecutive dates, they can confuse the ML model\n",
    "deltas = df['date'].diff()[1:] #Take the difference between consecutive dates\n",
    "gaps = deltas[deltas > timedelta(days=1)] #Filter gaps greater than 1 day\n",
    "#Print summary and details of each gap\n",
    "print(f'{len(gaps)} gaps with average gap duration: {gaps.mean()}') \n",
    "for i, g in gaps.items(): \n",
    "    gap_start = df.loc[i - 1, 'date']\n",
    "    print(f'Start: {gap_start.strftime(\"%Y-%m-%d\")} | Duration: {g}')\n",
    "#No relevant gaps are detected\n",
    "\n",
    "#Save processed dataframe to csv in current folder\n",
    "final_df.to_csv(\"final_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Task\n",
    "Now it is time to split the data, into a training, evaluation and test set. As a reminder, the date we are trying to predict snow fall for should constitute your test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "#The date we are trying to predict for\n",
    "test_date = str(dt.datetime.today()- dt.timedelta(days=20*365)).split(' ')[0]\n",
    "print(test_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select all the dates before the test date to create training and evaluation set\n",
    "train_eval_df = final_df[final_df['date'] < test_date]\n",
    "\n",
    "#Select all the dates which correspond to the date we are trying to predict for\n",
    "test_df = final_df[final_df['date'] == test_date]\n",
    "\n",
    "#Split train/eval set to obtain one set for training and one set for validation\n",
    "train_eval_df = train_eval_df.sort_values(by='date') #Sort set by date to maintain chronological order to avoid unrealistic forecasting\n",
    "#Define an index for splitting the train/eval set (90% of data for training and 10% for validation)\n",
    "split_idx = int(len(train_eval_df) * 0.9)\n",
    "#Declare training set and evaluation set \n",
    "train_df = train_eval_df.iloc[:split_idx] #Takes the first rows till split index position \n",
    "eval_df = train_eval_df.iloc[split_idx+1:] #Takes the rows after split index position and one day before the test date\n",
    "\n",
    "#Check the training and evaluation ranges to be sure they are correct and non-overlapping\n",
    "print(\"Training range:\", train_df['date'].min(), \"to\", train_df['date'].max())\n",
    "print(\"Evaluation range:\", eval_df['date'].min(), \"to\", eval_df['date'].max())\n",
    "\n",
    "#Define final set for training, evaluating and testing the model\n",
    "#Drop leakage-prone columns which indicate observed weather events, irrelevant columns (date) and target column (snow)\n",
    "X_train = train_df.drop(columns=['fog', 'rain', 'snow', 'hail', 'thunder', 'tornado', 'date'])\n",
    "X_eval = eval_df.drop(columns=['fog', 'rain', 'snow', 'hail', 'thunder', 'tornado', 'date'])\n",
    "X_test = test_df.drop(columns=['fog', 'rain', 'snow', 'hail', 'thunder','tornado', 'date'])\n",
    "y_train = train_df['snow']\n",
    "y_eval = eval_df['snow']\n",
    "y_test = test_df['snow']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "If you made it up to here all by yourself, you can use your prepared dataset to train an algorithm of your choice to forecast whether it will snow on the following date for each station in this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "#Compute class weights for unbalanced dataset\n",
    "print(y_train.value_counts()) #Class of no snowfall has more samples than class snowfall\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "#Normalize the data to improve prediction\n",
    "scaler = StandardScaler() #Create the scaler\n",
    "X_train_scaled = scaler.fit_transform(X_train)  #Fit to training set and transform it\n",
    "#Transform both evaluation and test set using same scale of training set\n",
    "X_eval_scaled = scaler.transform(X_eval)      \n",
    "X_test_scaled = scaler.transform(X_test)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are allowed to use any library you are comfortable with such as sklearn, tensorflow, keras etc. \n",
    "If you did not manage to finish part one feel free to use the data provided in 'coding_challenge.csv' Note that this data does not represent a solution to Part 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Test different parameters to feed the model for improving prediction\n",
    "params = {'n_estimators': [100, 200], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [5, 10, None], 'criterion' :['gini', 'entropy']}\n",
    "grid = GridSearchCV(RandomForestClassifier(random_state=42), params)\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "#Print best parameters for the model based on training set\n",
    "print(\"Best parameters:\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#Train random forest model on training dataset to predict snowfall\n",
    "RFC_model = RandomForestClassifier(random_state=42, \n",
    "                                   max_depth=5) #Tune the model based on GridSearchCV\n",
    "RFC_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check model's performance by predicting on evaluation set\n",
    "y_eval_pred = RFC_model.predict(X_eval_scaled)\n",
    "\n",
    "#Generate report for the model\n",
    "print(\"Evaluation Set Performance\")\n",
    "print(classification_report(y_eval, y_eval_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_eval, y_eval_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check model's perfomance on test set and generate report\n",
    "y_test_pred = RFC_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Final Test Set Performance\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred, labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#Train gradient boosting model to see if we can achieve better predictions \n",
    "XGBC_model = XGBClassifier(scale_pos_weight=class_weights[1]/class_weights[0], #Handle class imbalance\n",
    "                           booster='gblinear', \n",
    "                           missing=np.nan) \n",
    "XGBC_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check model's performance by predicting on evaluation set\n",
    "y_eval_pred = XGBC_model.predict(X_eval_scaled)\n",
    "\n",
    "#Generate report for the model\n",
    "print(\"Validation Set Performance\")\n",
    "print(classification_report(y_eval, y_eval_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_eval, y_eval_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check model's perfomance on test set and generate report\n",
    "y_test_pred = XGBC_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Final Test Set Performance\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred, labels=[0, 1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
